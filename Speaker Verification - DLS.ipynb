{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0f8c36e",
   "metadata": {},
   "source": [
    "### Speaker Verification System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dddb541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from random import *\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from torchvision import datasets\n",
    "import librosa\n",
    "from itertools import combinations\n",
    "import random\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45df39d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft(arr):\n",
    "    arr=librosa.stft(arr, n_fft=1024, hop_length=512)\n",
    "    arr=np.abs(arr).T\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5387fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/hw4_trs.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open('data/hw4_tes.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41811bb5",
   "metadata": {},
   "source": [
    "### Negative Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a05c0d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positive_sample(j,data):\n",
    "    pos_index=j*10\n",
    "    pos_data=data[pos_index:pos_index+10]\n",
    "    positive_list=[]\n",
    "    pos_combinations=list(itertools.combinations(range(10),2))\n",
    "    pos_samples=random.sample(pos_combinations,45)\n",
    "    for i in range(len(pos_samples)):\n",
    "        first_speaker=stft(pos_data[pos_combinations[i][0]])\n",
    "        second_speaker=stft(pos_data[pos_combinations[i][1]])\n",
    "        positive_list.append([first_speaker,second_speaker])\n",
    "    return positive_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0e9394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_samples(pos_speaker,data):\n",
    "    negative_list=[]\n",
    "    pos_index=pos_speaker * 10\n",
    "    neg_index=pos_index + 10\n",
    "    pos_speaker_arr=data[pos_index:neg_index]\n",
    "    neg_speaker_arr=data[:pos_index] + data[neg_index:]\n",
    "    neg_samples=random.sample(neg_speaker_arr,45)\n",
    "    for i in range(45):\n",
    "        positive_sample=random.choice(pos_speaker_arr)\n",
    "        first_speaker_arr=stft(positive_sample)\n",
    "        second_speaker_arr=stft(neg_samples[i])\n",
    "        negative_list.append([first_speaker_arr,second_speaker_arr])\n",
    "    return negative_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a6142a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "train_df=list(train_data)\n",
    "for i in range(0,50):\n",
    "    positive_lst = get_positive_sample(i,train_df)\n",
    "    negative_lst = negative_samples(i,train_df)\n",
    "    train=train + positive_lst + negative_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bbf0cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 2, 32, 513)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.stack(train)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f51eccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(x):\n",
    "    final_shape=np.zeros((2,45,513))\n",
    "    final_shape[:,:32]=x\n",
    "    return final_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04377686",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pad=[]\n",
    "for i in range(0,len(x_train)):\n",
    "    arr=padding(x_train[i])\n",
    "    x_train_pad.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45ba3edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4500"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b513f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_arr = [] \n",
    "for i in range(50):\n",
    "    y_tr = np.zeros(90, dtype = int)\n",
    "    y_tr[45:] += 1\n",
    "    target_arr.append(y_tr)\n",
    "target_arr = np.hstack(target_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de8bd676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2, 45, 513])\n"
     ]
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "dataset = torch.utils.data.TensorDataset(Tensor(x_train_pad), Tensor(target_train))\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "dataiter = iter(trainloader)\n",
    "inputs, targets = dataiter.next()\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "629a9b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "drop_prob=0.2\n",
    "\n",
    "class SiameseNetwork(nn.Module):# A simple implementation of siamese network, ResNet50 is used, and then connected by three fc layer.\n",
    "    def __init__(self,input_dim,hidden_dim,output_dim,dropout_prob,layers):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.input_size=input_dim\n",
    "        self.output_size=output_dim\n",
    "        self.dropout=dropout_prob\n",
    "        self.layer_size=layers\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.gru = nn.GRU(input_size=self.input_size,hidden_size=self.hidden_dim,num_layers=self.layer_size,batch_first=True, dropout=0.2)\n",
    "        self.fc1= nn.Linear(5760,self.output_size)\n",
    "        self.fc1= self.init_weights(self.fc1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu=nn.ReLU()\n",
    "        self.tanh=nn.Tanh()\n",
    "        \n",
    "    def init_weights(self,m):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        return m\n",
    "    \n",
    "    def forward(self,x1,x2):\n",
    "        h0_1 = torch.zeros(self.layer_size, x1.size(0),128)\n",
    "        h0_2 = torch.zeros(self.layer_size, x2.size(0),128)\n",
    "        output1,final_hidden_state = self.gru(x1,h0_1)\n",
    "        output1=self.tanh(output1)\n",
    "        output2,final_hidden_state=self.gru(x2,h0_2)\n",
    "        output2=self.tanh(output2)\n",
    "        output =torch.multiply(output1,output2)\n",
    "        output= output.reshape(output.size(0),-1)\n",
    "        output=self.fc1(output)\n",
    "        output=self.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9afd2d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiameseNetwork(\n",
       "  (gru): GRU(513, 128, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (fc1): Linear(in_features=5760, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (relu): ReLU()\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_model=SiameseNetwork(513,128,1,0.2,2)\n",
    "gru_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "43c84e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(gru_model.parameters(), lr=0.0001)\n",
    "loss_func = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "568c1c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 0.694581\n",
      "Epoch: 1, Train loss: 0.6876055\n",
      "Epoch: 2, Train loss: 0.6724918\n",
      "Epoch: 3, Train loss: 0.6127531\n",
      "Epoch: 4, Train loss: 0.5498557\n",
      "Epoch: 5, Train loss: 0.5083435\n",
      "Epoch: 6, Train loss: 0.4768887\n",
      "Epoch: 7, Train loss: 0.4499564\n",
      "Epoch: 8, Train loss: 0.4278079\n",
      "Epoch: 9, Train loss: 0.4066438\n",
      "Epoch: 10, Train loss: 0.3875279\n",
      "Epoch: 11, Train loss: 0.3714248\n",
      "Epoch: 12, Train loss: 0.353963\n",
      "Epoch: 13, Train loss: 0.3383491\n",
      "Epoch: 14, Train loss: 0.3209416\n",
      "Epoch: 15, Train loss: 0.3064107\n",
      "Epoch: 16, Train loss: 0.2900203\n",
      "Epoch: 17, Train loss: 0.2768416\n",
      "Epoch: 18, Train loss: 0.2612205\n",
      "Epoch: 19, Train loss: 0.2483585\n",
      "Epoch: 20, Train loss: 0.2366068\n",
      "Epoch: 21, Train loss: 0.2245398\n",
      "Epoch: 22, Train loss: 0.2126477\n",
      "Epoch: 23, Train loss: 0.2032895\n",
      "Epoch: 24, Train loss: 0.194182\n",
      "Epoch: 25, Train loss: 0.1863022\n",
      "Epoch: 26, Train loss: 0.1769837\n",
      "Epoch: 27, Train loss: 0.1702463\n",
      "Epoch: 28, Train loss: 0.1653714\n",
      "Epoch: 29, Train loss: 0.157456\n",
      "Epoch: 30, Train loss: 0.147174\n",
      "Epoch: 31, Train loss: 0.1383915\n",
      "Epoch: 32, Train loss: 0.131533\n",
      "Epoch: 33, Train loss: 0.1310775\n",
      "Epoch: 34, Train loss: 0.1210131\n",
      "Epoch: 35, Train loss: 0.1220731\n",
      "Epoch: 36, Train loss: 0.1150548\n",
      "Epoch: 37, Train loss: 0.1121494\n",
      "Epoch: 38, Train loss: 0.1031696\n",
      "Epoch: 39, Train loss: 0.1003226\n",
      "Epoch: 40, Train loss: 0.0965314\n",
      "Epoch: 41, Train loss: 0.1051177\n",
      "Epoch: 42, Train loss: 0.0892521\n",
      "Epoch: 43, Train loss: 0.0863566\n",
      "Epoch: 44, Train loss: 0.0834094\n",
      "Epoch: 45, Train loss: 0.0837196\n",
      "Epoch: 46, Train loss: 0.0810949\n",
      "Epoch: 47, Train loss: 0.0698463\n",
      "Epoch: 48, Train loss: 0.0757854\n",
      "Epoch: 49, Train loss: 0.0745906\n",
      "Epoch: 50, Train loss: 0.0642471\n",
      "Epoch: 51, Train loss: 0.0595209\n",
      "Epoch: 52, Train loss: 0.053529\n",
      "Epoch: 53, Train loss: 0.0501739\n",
      "Epoch: 54, Train loss: 0.0507504\n",
      "Epoch: 55, Train loss: 0.0455267\n",
      "Epoch: 56, Train loss: 0.049363\n",
      "Epoch: 57, Train loss: 0.0440708\n",
      "Epoch: 58, Train loss: 0.0410721\n",
      "Epoch: 59, Train loss: 0.0432997\n",
      "Epoch: 60, Train loss: 0.0401851\n",
      "Epoch: 61, Train loss: 0.0372382\n",
      "Epoch: 62, Train loss: 0.0328714\n",
      "Epoch: 63, Train loss: 0.0293129\n",
      "Epoch: 64, Train loss: 0.0228041\n",
      "Epoch: 65, Train loss: 0.0236252\n",
      "Epoch: 66, Train loss: 0.0208529\n",
      "Epoch: 67, Train loss: 0.0174672\n",
      "Epoch: 68, Train loss: 0.0217809\n",
      "Epoch: 69, Train loss: 0.140478\n",
      "Epoch: 70, Train loss: 0.3266089\n",
      "Epoch: 71, Train loss: 0.0808071\n",
      "Epoch: 72, Train loss: 0.0455424\n",
      "Epoch: 73, Train loss: 0.0259964\n",
      "Epoch: 74, Train loss: 0.0208158\n"
     ]
    }
   ],
   "source": [
    "e = 75\n",
    "final_output = []\n",
    "for epoch in range(e):\n",
    "    train_loss = []\n",
    "    for data, label in trainloader:\n",
    "        x=data[:,0]\n",
    "        y=data[:,1]\n",
    "        outputs = gru_model(x,y)\n",
    "        loss = loss_func(outputs.squeeze(), label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        if epoch == e-1:\n",
    "            final_output.append(outputs)\n",
    "    if epoch == e-1:\n",
    "        final_output = torch.cat(final_output)\n",
    "    print('Epoch: {}, Train loss: {}'.format(epoch, np.round(np.mean(train_loss),7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d22ee9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test DataSet Preparation\n",
    "test = []\n",
    "test_df=list(test_data)\n",
    "for i in range(0,20):\n",
    "    positive_lst = get_positive_sample(i,test_df)\n",
    "    negative_lst = negative_samples(i,test_df)\n",
    "    test=test + positive_lst + negative_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4c2ce09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 2, 45, 513)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test=np.stack(test)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "10a3e56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = [] \n",
    "for i in range(20):\n",
    "    y_test= np.zeros(90, dtype = int)\n",
    "    y_test[45:] += 1\n",
    "    test_arr.append(y_test)\n",
    "y_test_pad = np.hstack(test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cffbc68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2, 45, 513])\n"
     ]
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "dataset = torch.utils.data.TensorDataset(Tensor(x_test), Tensor(y_test_pad))\n",
    "testloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "dataiter = iter(testloader)\n",
    "inputs, targets = dataiter.next()\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d574adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=[]\n",
    "test_accuracy=[]\n",
    "for images,labels in testloader:\n",
    "    x=images[:,0]\n",
    "    y=images[:,1]\n",
    "    gru_model.eval()\n",
    "    outputs = gru_model(x,y)\n",
    "    prediction.append(outputs)\n",
    "    outputs=torch.round(outputs.squeeze())\n",
    "#     print(outputs)\n",
    "    test_accuracy.append((outputs == labels).sum().item() / outputs.size(0))\n",
    "prediction_valid=torch.cat(prediction,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "de78efc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7001\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: {}'.format(np.round(np.mean(test_accuracy),4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053120f7",
   "metadata": {},
   "source": [
    "### We get a test accuracy of 70%`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
